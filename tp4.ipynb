{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.training.example import Example\n",
    "from spacy.pipeline.tagger import Tagger\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to update a dependency parser starting off with a blank model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to train our parsers to understand new semantic relationships or dependencies between words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created blank 'en' model\n",
      "find enough hotels with good wifi\n",
      "[('find', 'ROOT', 'find'), ('enough', 'QUANTITY', 'hotels'), ('hotels', 'PLACE', 'find'), ('good', 'QUALITY', 'wifi'), ('wifi', 'ATTRIBUTE', 'hotels')]\n",
      "find some gyms near work\n",
      "[('find', 'ROOT', 'find'), ('some', 'QUANTITY', 'gyms'), ('gyms', 'PLACE', 'find'), ('near', 'QUALITY', 'work'), ('work', 'ATTRIBUTE', 'gyms')]\n",
      "show me many hotels in berlin\n",
      "[('show', 'ROOT', 'show'), ('many', 'QUANTITY', 'hotels'), ('hotels', 'PLACE', 'show'), ('berlin', 'LOCATION', 'hotels')]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import unicode_literals, print_function\n",
    "\n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "\n",
    "\n",
    "# training data: texts, heads and dependency labels\n",
    "# for no relation, we simply chose an arbitrary dependency label, e.g. '-'\n",
    "TRAIN_DATA = [\n",
    "    (\n",
    "        \"find some cafes with great wifi\",\n",
    "        {\n",
    "            \"heads\": [0, 2, 0, 5, 5, 2],  # index of token head\n",
    "            \"deps\": [\"ROOT\", \"QUANTITY\", \"PLACE\", \"-\", \"QUALITY\", \"ATTRIBUTE\"],\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"find a few hotel near the beach\",\n",
    "        {\n",
    "            \"heads\": [0, 3, 3, 0, 5, 5, 2],\n",
    "            \"deps\": [\"ROOT\", \"-\", \"QUANTITY\", \"PLACE\", \"QUALITY\", \"-\", \"ATTRIBUTE\"],\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"find me numerous gyms that are open late\",\n",
    "        {\n",
    "            \"heads\": [0, 0, 3, 0, 5, 3, 5, 5],\n",
    "            \"deps\": [\"ROOT\",\"-\",\"QUANTITY\",\"PLACE\",\"-\",\"-\",\"ATTRIBUTE\",\"TIME\"],\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"show me many stores that sell flowers\",\n",
    "        {\n",
    "            \"heads\": [0, 0, 3, 0, 3, 3, 3],  # attach \"flowers\" to store!\n",
    "            \"deps\": [\"ROOT\", \"-\", \"QUANTITY\", \"PLACE\", \"-\", \"-\", \"PRODUCT\"],\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"walk a whole day in london\",\n",
    "        {\n",
    "            \"heads\": [0, 3, 3, 0, 3, 3],\n",
    "            \"deps\": [\"ROOT\", \"-\", \"QUANTITY\", \"TIME\", \"-\", \"LOCATION\"],\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"walk enough hours in london\",\n",
    "        {\n",
    "            \"heads\": [0, 2, 0, 2, 2],\n",
    "            \"deps\": [\"ROOT\", \"QUANTITY\", \"TIME\", \"-\", \"LOCATION\"],\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"show me all the hostels in berlin\",\n",
    "        {\n",
    "            \"heads\": [0, 0, 4, 4, 0, 4, 4],\n",
    "            \"deps\": [\"ROOT\", \"-\", \"QUANTITY\", \"-\", \"PLACE\", \"-\", \"LOCATION\"],\n",
    "        },\n",
    "    ),\n",
    "    (\n",
    "        \"give me half the money in your pocket\",\n",
    "        {\n",
    "            \"heads\": [0, 0, 4, 4, 0, 7, 7, 4],\n",
    "            \"deps\": [\"ROOT\",\"-\",\"QUANTITY\",\"-\",\"ATTRIBUTE\",\"-\",\"-\",\"LOCATION\"],\n",
    "        },\n",
    "    ),\n",
    "]\n",
    "\n",
    "\n",
    "# @plac.annotations(\n",
    "#     model=(\"Model name. Defaults to blank 'en' model.\", \"option\", \"m\", str),\n",
    "#     output_dir=(\"Optional output directory\", \"option\", \"o\", Path),\n",
    "#     n_iter=(\"Number of training iterations\", \"option\", \"n\", int),\n",
    "# )\n",
    "def main(model=None, output_dir=None, n_iter=100):\n",
    "    \"\"\"Load the model, set up the pipeline and train the parser.\"\"\"\n",
    "    if model is not None:\n",
    "        nlp = spacy.load(model)  # load existing spaCy model\n",
    "        print(\"Loaded model '%s'\" % model)\n",
    "    else:\n",
    "        nlp = spacy.blank(\"en\")  # create blank Language class\n",
    "        print(\"Created blank 'en' model\")\n",
    "\n",
    "    # We'll use the built-in dependency parser class, but we want to create a\n",
    "    # fresh instance â€“ just in case.\n",
    "    if \"parser\" in nlp.pipe_names:\n",
    "        nlp.remove_pipe(\"parser\")\n",
    "    # parser = nlp.create_pipe(\"parser\")\n",
    "    parser = nlp.add_pipe('parser', first=True)\n",
    "\n",
    "    for text, annotations in TRAIN_DATA:\n",
    "        for dep in annotations.get(\"deps\", []):\n",
    "            parser.add_label(dep)\n",
    "\n",
    "    pipe_exceptions = [\"parser\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
    "    other_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]\n",
    "    with nlp.disable_pipes(*other_pipes):  # only train parser\n",
    "        optimizer = nlp.begin_training()\n",
    "        for itn in range(n_iter):\n",
    "            random.shuffle(TRAIN_DATA)\n",
    "            losses = {}\n",
    "            # batch up the examples using spaCy's minibatch\n",
    "            for batch in minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001)):\n",
    "                examples = []\n",
    "                for text, annotations in batch:\n",
    "                    doc = nlp.make_doc(text)\n",
    "                    example = Example.from_dict(doc, annotations)\n",
    "                    examples.append(example)\n",
    "                nlp.update(examples, drop=0.5, losses=losses)\n",
    "            # print(\"Losses\", losses)\n",
    "\n",
    "    # test the trained model\n",
    "    test_model(nlp)\n",
    "\n",
    "    # save model to output directory\n",
    "    if output_dir is not None:\n",
    "        output_dir = Path(output_dir)\n",
    "        if not output_dir.exists():\n",
    "            output_dir.mkdir()\n",
    "        nlp.to_disk(output_dir)\n",
    "        print(\"Saved model to\", output_dir)\n",
    "\n",
    "        # test the saved model\n",
    "        print(\"Loading from\", output_dir)\n",
    "        nlp2 = spacy.load(output_dir)\n",
    "        test_model(nlp2)\n",
    "\n",
    "\n",
    "def test_model(nlp):\n",
    "    texts = [\n",
    "        \"find enough hotels with good wifi\",\n",
    "        \"find some gyms near work\",\n",
    "        \"show me many hotels in berlin\",\n",
    "    ]\n",
    "    docs = nlp.pipe(texts)\n",
    "    for doc in docs:\n",
    "        print(doc.text)\n",
    "        print([(t.text, t.dep_, t.head.text) for t in doc if t.dep_ != \"-\"])\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

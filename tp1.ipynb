{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this is happening in 1998 !!! :)\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"this is happening in 1998 !!! :)\") #contains lexical entities (token) with properties of each\n",
    "print(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  |  this -->  PRON --- stop? True --- lemma: this\n",
      "5  |  is -->  AUX --- stop? True --- lemma: be\n",
      "8  |  happening -->  VERB --- stop? False --- lemma: happen\n",
      "18  |  in -->  ADP --- stop? True --- lemma: in\n",
      "21  |  1998 -->  NUM --- stop? False --- lemma: 1998\n",
      "26  |  ! -->  PUNCT --- stop? False --- lemma: !\n",
      "27  |  ! -->  PUNCT --- stop? False --- lemma: !\n",
      "28  |  ! -->  PUNCT --- stop? False --- lemma: !\n",
      "30  |  :) -->  PUNCT --- stop? False --- lemma: :)\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token.idx, ' | ',token.text, '--> ', token.pos_, '--- stop?', token.is_stop, '--- lemma:', token.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_text = (\n",
    "     \"Gus Proto is a Python developer currently\"\n",
    "     \" working for a London-based Fintech company. He is\"\n",
    "     \" interested in learning Natural Language Processing.\"\n",
    "     \" There is a developer conference happening on 21 July\"\n",
    "     ' 2019 in London. It is titled \"Applications of Natural'\n",
    "     ' Language Processing\". There is a helpline number'\n",
    "     \" available at +44-1234567891. Gus is helping organize it.\"\n",
    "     \" He keeps organizing local Python meetups and several\"\n",
    "     \" internal talks at his workplace. Gus is also presenting\"\n",
    "     ' a talk. The talk will introduce the reader about \"Use'\n",
    "     ' cases of Natural Language Processing in Fintech\".'\n",
    "     \" Apart from his work, he is very passionate about music.\"\n",
    "     \" Gus is learning to play the Piano. He has enrolled\"\n",
    "     \" himself in the weekend batch of Great Piano Academy.\"\n",
    "     \" Great Piano Academy is situated in Mayfair or the City\"\n",
    "     \" of London and has world-class piano instructors.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gus Proto is a Python developer currently working for a London-based Fintech company. He is interested in learning Natural Language Processing. There is a developer conference happening on 21 July 2019 in London. It is titled \"Applications of Natural Language Processing\". There is a helpline number available at +44-1234567891. Gus is helping organize it. He keeps organizing local Python meetups and several internal talks at his workplace. Gus is also presenting a talk. The talk will introduce the reader about \"Use cases of Natural Language Processing in Fintech\". Apart from his work, he is very passionate about music. Gus is learning to play the Piano. He has enrolled himself in the weekend batch of Great Piano Academy. Great Piano Academy is situated in Mayfair or the City of London and has world-class piano instructors.\n"
     ]
    }
   ],
   "source": [
    "complete_doc = nlp(complete_text)\n",
    "print(complete_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 13 sentences\n"
     ]
    }
   ],
   "source": [
    "#Sentences detection\n",
    "sentences = list(complete_doc.sents)\n",
    "print(\"There are\",len(sentences),\"sentences\")\n",
    "#for sentence in sentences:\n",
    "#     print(f\"{sentence[:5]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lower casing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase_sentences(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    modified_text = \"\"\n",
    "\n",
    "    for sent in doc.sents:\n",
    "        modified_text += sent.text.lower()+ \" \" \n",
    "\n",
    "    return modified_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gus proto is a python developer currently working for a london-based fintech company. he is interested in learning natural language processing. there is a developer conference happening on 21 july 2019 in london. it is titled \"applications of natural language processing\". there is a helpline number available at +44-1234567891. gus is helping organize it. he keeps organizing local python meetups and several internal talks at his workplace. gus is also presenting a talk. the talk will introduce the reader about \"use cases of natural language processing in fintech\". apart from his work, he is very passionate about music. gus is learning to play the piano. he has enrolled himself in the weekend batch of great piano academy. great piano academy is situated in mayfair or the city of london and has world-class piano instructors. \n"
     ]
    }
   ],
   "source": [
    "\n",
    "complete_text = lowercase_sentences(complete_text)\n",
    "print(complete_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removal of Punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    modified_tokens = [token.text for token in doc if not token.is_punct]\n",
    "\n",
    "    modified_text = \" \".join(modified_tokens)\n",
    "\n",
    "    return modified_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gus proto is a python developer currently working for a london based fintech company he is interested in learning natural language processing there is a developer conference happening on 21 july 2019 in london it is titled applications of natural language processing there is a helpline number available at +44 1234567891 gus is helping organize it he keeps organizing local python meetups and several internal talks at his workplace gus is also presenting a talk the talk will introduce the reader about use cases of natural language processing in fintech apart from his work he is very passionate about music gus is learning to play the piano he has enrolled himself in the weekend batch of great piano academy great piano academy is situated in mayfair or the city of london and has world class piano instructors\n"
     ]
    }
   ],
   "source": [
    "complete_text = remove_punctuation(complete_text)\n",
    "print(complete_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removal of Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    modified_tokens = [token.text for token in doc if not token.is_stop]\n",
    "\n",
    "    modified_text = \" \".join(modified_tokens)\n",
    "\n",
    "    return modified_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gus proto python developer currently working london based fintech company interested learning natural language processing developer conference happening 21 july 2019 london titled applications natural language processing helpline number available +44 1234567891 gus helping organize keeps organizing local python meetups internal talks workplace gus presenting talk talk introduce reader use cases natural language processing fintech apart work passionate music gus learning play piano enrolled weekend batch great piano academy great piano academy situated mayfair city london world class piano instructors\n"
     ]
    }
   ],
   "source": [
    "complete_text = remove_stopwords(complete_text)\n",
    "print(complete_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removal of Frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def remove_frequent_words(text, num_most_common=10):\n",
    "    # Parse the input text using spaCy\n",
    "    doc = nlp(text)\n",
    "\n",
    "    words = [token.text for token in doc]\n",
    "    word_freq = Counter(words)\n",
    "    print(word_freq)\n",
    "\n",
    "    most_common_words = [word for word, freq in word_freq.most_common(num_most_common)]\n",
    "\n",
    "    modified_tokens = [token.text for token in doc if token.text not in most_common_words]\n",
    "\n",
    "    modified_text = \" \".join(modified_tokens)\n",
    "\n",
    "    return modified_text, most_common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'gus': 4, 'piano': 4, 'london': 3, 'natural': 3, 'language': 3, 'processing': 3, 'python': 2, 'developer': 2, 'fintech': 2, 'learning': 2, 'talk': 2, 'great': 2, 'academy': 2, 'proto': 1, 'currently': 1, 'working': 1, 'based': 1, 'company': 1, 'interested': 1, 'conference': 1, 'happening': 1, '21': 1, 'july': 1, '2019': 1, 'titled': 1, 'applications': 1, 'helpline': 1, 'number': 1, 'available': 1, '+44': 1, '1234567891': 1, 'helping': 1, 'organize': 1, 'keeps': 1, 'organizing': 1, 'local': 1, 'meetups': 1, 'internal': 1, 'talks': 1, 'workplace': 1, 'presenting': 1, 'introduce': 1, 'reader': 1, 'use': 1, 'cases': 1, 'apart': 1, 'work': 1, 'passionate': 1, 'music': 1, 'play': 1, 'enrolled': 1, 'weekend': 1, 'batch': 1, 'situated': 1, 'mayfair': 1, 'city': 1, 'world': 1, 'class': 1, 'instructors': 1})\n",
      "['gus', 'piano', 'london', 'natural', 'language', 'processing', 'python', 'developer', 'fintech', 'learning']\n",
      "proto currently working based company interested conference happening 21 july 2019 titled applications helpline number available +44 1234567891 helping organize keeps organizing local meetups internal talks workplace presenting talk talk introduce reader use cases apart work passionate music play enrolled weekend batch great academy great academy situated mayfair city world class instructors\n"
     ]
    }
   ],
   "source": [
    "complete_text, most_common_words = remove_frequent_words(complete_text)\n",
    "print(most_common_words)\n",
    "print(complete_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removal of Rare words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_rare_words(text, min_frequency=2):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    words = [token.text for token in doc]\n",
    "    word_freq = Counter(words)\n",
    "\n",
    "    rare_words = [word for word, freq in word_freq.items() if freq < min_frequency]\n",
    "\n",
    "    modified_tokens = [token.text for token in doc if token.text not in rare_words]\n",
    "\n",
    "    modified_text = \" \".join(modified_tokens)\n",
    "\n",
    "    return modified_text, rare_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'talk': 2, 'great': 2, 'academy': 2, 'proto': 1, 'currently': 1, 'working': 1, 'based': 1, 'company': 1, 'interested': 1, 'conference': 1, 'happening': 1, '21': 1, 'july': 1, '2019': 1, 'titled': 1, 'applications': 1, 'helpline': 1, 'number': 1, 'available': 1, '+44': 1, '1234567891': 1, 'helping': 1, 'organize': 1, 'keeps': 1, 'organizing': 1, 'local': 1, 'meetups': 1, 'internal': 1, 'talks': 1, 'workplace': 1, 'presenting': 1, 'introduce': 1, 'reader': 1, 'use': 1, 'cases': 1, 'apart': 1, 'work': 1, 'passionate': 1, 'music': 1, 'play': 1, 'enrolled': 1, 'weekend': 1, 'batch': 1, 'situated': 1, 'mayfair': 1, 'city': 1, 'world': 1, 'class': 1, 'instructors': 1})\n",
      "['talk', 'great', 'academy', 'proto', 'currently', 'working', 'based', 'company', 'interested', 'conference']\n",
      "happening 21 july 2019 titled applications helpline number available +44 1234567891 helping organize keeps organizing local meetups internal talks workplace presenting introduce reader use cases apart work passionate music play enrolled weekend batch situated mayfair city world class instructors\n"
     ]
    }
   ],
   "source": [
    "complete_text, rare_words = remove_frequent_words(complete_text)\n",
    "print(rare_words)\n",
    "print(complete_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "def stem_text(text):\n",
    "    doc = nlp(text)\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(token.text) for token in doc]\n",
    "\n",
    "    stemmed_text = \" \".join(stemmed_tokens)\n",
    "\n",
    "    return stemmed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happen 21 juli 2019 titl applic helplin number avail +44 1234567891 help organ keep organ local meetup intern talk workplac present introduc reader use case apart work passion music play enrol weekend batch situat mayfair citi world class instructor\n"
     ]
    }
   ],
   "source": [
    "complete_text = stem_text(complete_text)\n",
    "\n",
    "# Print the stemmed text\n",
    "print(complete_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    lemmatized_tokens = [token.lemma_ for token in doc]\n",
    "    lemmatized_text = \" \".join(lemmatized_tokens)\n",
    "\n",
    "    return lemmatized_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "happen 21 juli 2019 titl applic helplin number avail +44 1234567891 help organ keep organ local meetup intern talk workplac present introduc reader use case apart work passion music play enrol weekend batch situat mayfair citi world class instructor\n"
     ]
    }
   ],
   "source": [
    "lemmatized_text = lemmatize_text(complete_text)\n",
    "\n",
    "# Print the lemmatized text\n",
    "print(lemmatized_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
